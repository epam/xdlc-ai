---
title: Coding Assistants
---

import MarkdownSortableTable from '../components/MarkdownSortableTable';

Coding assistants are AI-driven tools designed to enhance software development by providing code suggestions, generating documentation, and more. These tools utilize both chat and completion models, integrated into popular IDEs like Visual Studio Code and JetBrains. This page presents a leaderboard of various coding assistants,. The benchmark assesses performance across multiple categories, such as code generation, bug fixing, test creation, and more complex tasks like solution migration and DevOps. Regular updates ensure the leaderboard reflects the latest advancements in AI technology. For detailed evaluation criteria, visit [this repo](https://github.com/epam/AIRUN-Engineering-Benchmark/tree/main).

# Coding Assistants Leaderboard

    <MarkdownSortableTable markdown={`
    | Category                        | Test Date     | Low Complexity      | Medium Complexity      | Total Score                           |
    |---------------------------------|---------------|---------------------|------------------------|---------------------------------------|
    | Cursor + Sonnet 3.5             | Sep 2024      | 97%                 | 88%                    | 96%                                   |
    | Continue + GPT4o                | Jul 2024      | 93%                 | 90%                    | 92%                                   |
    | GitHub Copilot + Sonnet 3.5     | Nov 2024      | 90%                 | 76%                    | 88%                                   |
    | GitHub Copilot + o1-mini        | Nov 2024      | 88%                 | 88%                    | 88%                                   |
    | GitHub Copilot + GPT4o          | Dec 2024      | 89%                 | 78%                    | 88%                                   |
    | Gemini                          | Sep 2024      | 87%                 | 68%                    | 83%                                   |
    | GitHub Copilot + GPT4o          | Aug 2024      | 84%                 | 70%                    | 81%                                   |
    | Amazon Q                        | Sep 2024      | 82%                 | 76%                    | 81%                                   |
    | Cursor*                         | Jul 2024      | 81%                 | 78%                    | 80%                                   |
    | Sourcegraph Cody                | Jul 2024      | 71%                 | 76%                    | 71%                                   |
    | Continue + Sonnet 3.5           | Sep 2024      | 62%                 | 76%                    | 64%                                   |
    | CodiumAI                        | Jun 2024      | 49%                 | 63%                    | 52%                                   |
    `} />

> Tested as plugins for VS Code with the exception of Cursor which is an IDE itself (VSCode fork).

## Brief Summaries

- **Cursor + Sonnet 3.5**: Separate IDE (private build of VS Code) that has rich and efficient Gen AI capabilities tightly integrated into the IDE user journeys and scoring very high numbers in EPAM Benchmark. Although raises serious concerns being a niche IDE on its own - rarely a developer will code in VS Code, even more rarely - in some niche IDE.
- **Continue + GPT4o**: Open-source plugin for VS Code and JetBrains IDEs that scores the highest numbers in EPAM benchmark in combination with GPT-4o. Very fast and efficient. Is worth considering as alternative to non-agentic Copilot.
- **GitHub Copilot + Sonnet 3.5**: As of November 2024 looks like an experimental feature of Copilot as not all tests can pass. Good score overall but slower than o1.
- **GitHub Copilot + o1-mini**: Fast and accurate across all usecases. Score a bit lower than the leading combination Cursor + Sonnet 3.5.
- **GitHub Copilot + GPT4o**: Copilot + GPT4o is similar to Copilot +o1mini. While Copilot +o1mini generates more code examples and documentation in the chat window, Copilot + GPT4o provides a more concise output. Both are approximately equal in terms of response generation speed.
- **Gemini**: Good score overall but lower than Copilot + o1. Very close to Amazon Q.
- **GitHub Copilot + GPT4o**: Used to be a leader in the score across 3 major vendors but now has been likely overtaken by AWS Amazon Q by a tiny margin. According to the tests the **chat is much more capable than code completion**. Has got some useful chat commands however does not provide a developer agent like Amazon Q.
- **Amazon Q**: Initially a laggard but recently Amazon likely did huge investments to improve this technology - the quality of answers increased approx. on 10-20% and it provides a unique developer agent - the only major vendor that released this tech - able to solve high-level tasks by generating a plan and creating code for it - it rendered much better results than its competitor Codium AI, although seemingly its dev agent can't solve all tasks. On the negative side it's code completion is much less accurate unlike its chat and responses were slow. Overall the tests score is on the level or even better than Copilot.
- **Cursor***: Separate IDE (private build of VS Code) that has rich and efficient Gen AI capabilities tightly integrated into the IDE user journeys and scoring very high numbers in EPAM Benchmark. Although raises serious concerns being a niche IDE on its own - rarely a developer will code in VS Code, even more rarely - in some niche IDE.
- **Sourcegraph Cody**: Niche product - a plugin for VS Code and a standalone website plus an enterprise offering. Scored good marks in EPAM Benchmark although worse than Copilot especially in code completion. Especially good at indexing a project locally and automatically providing necessary embeddings. A separate website has got a Code Search feature that answers questions on open-source repositories. Is worth investigating deeper for cases when a client needs to index a whole private repository locally - likely an expensive Enterprise version is needed for such case.
- **Continue + Sonnet 3.5**: Open-source plugin for VS Code and JetBrains IDEs that scores the highest numbers in EPAM benchmark in combination with Sonnet 3.5. Very fast and efficient. Is worth considering as alternative to non-agentic Copilot.
- **CodiumAI**: Niche product (VS Code and JetBrains IDEs Plugin) that has many capabilities including agentic features but did not impress overall in any of areas. Benchmark score is low. Can generate not bad unit test suites - but this is on the level of major players in the field. Code reviews functionality is worse by quality then unit tests generation.

### TBD

- Improve intro
- How many tests exactly
- Describe columns
- Explain completion and chat models, explain categories
- Add more tables
- Samples of tasks