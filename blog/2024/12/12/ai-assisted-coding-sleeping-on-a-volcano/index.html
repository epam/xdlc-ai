<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.6.3">
<title data-rh="true">AI-assisted coding, Sleeping on a Volcano | &lt; xdlc.ai /&gt;</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="AI-assisted coding, Sleeping on a Volcano | &lt; xdlc.ai /&gt;"><meta data-rh="true" name="description" content="logo"><meta data-rh="true" property="og:description" content="logo"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-12-12T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/maxim-saplin"><meta data-rh="true" property="article:tag" content="Developers,xdlc.ai"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://your-docusaurus-site.example.com/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano","mainEntityOfPage":"https://your-docusaurus-site.example.com/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano","url":"https://your-docusaurus-site.example.com/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano","headline":"AI-assisted coding, Sleeping on a Volcano","name":"AI-assisted coding, Sleeping on a Volcano","description":"logo","datePublished":"2024-12-12T00:00:00.000Z","author":{"@type":"Person","name":"Maxim Saplin","description":"Front End Engineer @ EPAM","url":"https://github.com/maxim-saplin","image":"https://avatars.githubusercontent.com/u/7947027?v=4"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://your-docusaurus-site.example.com/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="&lt; xdlc.ai /&gt; RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="&lt; xdlc.ai /&gt; Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D1CPVQLTWE"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-D1CPVQLTWE",{anonymize_ip:!0})</script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous">
<link href="https://fonts.googleapis.com/css2?family=Space+Mono:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet"><link rel="stylesheet" href="/assets/css/styles.1855dacd.css">
<script src="/assets/js/runtime~main.4cc0e18d.js" defer="defer"></script>
<script src="/assets/js/main.79ebbd2e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">&lt; xdlc.ai /&gt;</b></a><a class="navbar__item navbar__link" href="/docs/Tips-and-tricks">Cookbook</a><a class="navbar__item navbar__link" href="/llms">LLMs</a><a class="navbar__item navbar__link" href="/coding-assistants">Coding Assistants</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano">AI-assisted coding, Sleeping on a Volcano</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/welcome">Welcome</a></li></ul></div></nav></aside><main class="col col--7"><article><header><h1 class="title_f1Hy">AI-assisted coding, Sleeping on a Volcano</h1><div class="container_mt6G margin-vert--md"><time datetime="2024-12-12T00:00:00.000Z">December 12, 2024</time> Â· <!-- -->11 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/maxim-saplin" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/7947027?v=4" alt="Maxim Saplin"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/maxim-saplin" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Maxim Saplin</span></a></div><small class="authorTitle_nd0D" title="Front End Engineer @ EPAM">Front End Engineer @ EPAM</small><div class="authorSocials_rSDt"><a href="https://x.com/msmxm" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="X"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="none" viewBox="0 0 1200 1227" class="authorSocialLink_owbf xSvg_y3PF" style="--dark:#000;--light:#fff"><path d="M714.163 519.284 1160.89 0h-105.86L667.137 450.887 357.328 0H0l468.492 681.821L0 1226.37h105.866l409.625-476.152 327.181 476.152H1200L714.137 519.284h.026ZM569.165 687.828l-47.468-67.894-377.686-540.24h162.604l304.797 435.991 47.468 67.894 396.2 566.721H892.476L569.165 687.854v-.026Z"></path></svg></a><a href="https://github.com/maxim-saplin" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="GitHub"><svg viewBox="0 0 256 250" width="1em" height="1em" class="authorSocialLink_owbf githubSvg_Uu4N" xmlns="http://www.w3.org/2000/svg" style="--dark:#000;--light:#fff" preserveAspectRatio="xMidYMid"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"></path></svg></a></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p><img decoding="async" loading="lazy" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4yi7x4r44r6f48rbh72p.png" alt="logo" class="img_ev3q"></p>
<blockquote>
<p>I started this post with the intention to deliver a simple message... AI tools bring convenience, people get lazier and copy/paste hallucinated code, and flaws get missed and not discovered until later. Yet it happened to be longer and deeper.</p>
</blockquote>
<p>If you are working in a large software company and <strong>there&#x27;s a team requesting an AI Chat Bot</strong> for their enterprise project (e.g. copy-and-paste stack traces while debugging errors)... Or they want to use <strong>AI coding assistant</strong> in their IDEs (and keep the generated code in production Git)... After the question of tools cost is sorted and you are cleared by Finance, you will likely be pulled into some &quot;fear-driven&quot; meeting with legal/compliance/IT-security discussing one of the topics:</p>
<ul>
<li>Data security</li>
<li>Privacy</li>
<li>Copyright</li>
</ul>
<p>Nobody wants to be taken accountable for the (potential) failures brought by GenAI or 3rd parties in the supply chain. Those boring and trivial questions consume most of the time in discussions (is it yet another manifestation of <a href="https://en.wiktionary.org/wiki/bikeshedding" target="_blank" rel="noopener noreferrer">bikeshedding</a>?). Yet a more nuanced (and IMO important) subject how AI can affect the quality of the end product is ignored.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="change-of-the-paradigm">Change of the Paradigm<a href="#change-of-the-paradigm" class="hash-link" aria-label="Direct link to Change of the Paradigm" title="Direct link to Change of the Paradigm">â</a></h2>
<p>There&#x27;s a joke: &quot;Before ChatGPT I spent my time writing code. Now I spend it debugging and fixing the generated one&quot;.</p>
<p>Providing the dev team with GH CoPilot subscriptions doesn&#x27;t guarantee getting more with less. It might happen that neither the quality nor quantity of the output will improve. The effects of GenAI adoption in engineering workflows might be more nuanced and deferred.</p>
<p>One popular view on how Generative AI is transforming software development goes as follows: let the engineers focus on the creative aspects of the job and delegate the tedious task of writing code to a GPT/LLM. <strong>This AI-coding paradigm assumes the shift in the dev&#x27;s job description: from typing in program code to writing instructions and reviewing the generated result, directing the AI model into producing the desired output.</strong></p>
<p>Here&#x27;s Andrej Karpathy&#x27;s <a href="https://twitter.com/karpathy/status/1767598414945292695" target="_blank" rel="noopener noreferrer">recent quote</a>:</p>
<blockquote>
<p>In any case, software engineering is on track to change substantially. And it will look a lot more like supervising the automation, while pitching in high-level commands, ideas, or progression strategies, in English.</p>
</blockquote>
<p>And here&#x27;s a quote from <strong>AI Challenges and Opportunities for Leadership</strong> LinkedIn course (if you haven&#x27;t heard, LinkedIn recently released <a href="https://www.linkedin.com/business/talent/blog/talent-acquisition/250-free-ai-courses" target="_blank" rel="noopener noreferrer">250 free AI courses</a>):</p>
<blockquote>
<p>&quot;... productivity tools that speed up work while enhancing output quality&quot;.
<img decoding="async" loading="lazy" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ulh3m7lej10ly4dqpwpz.png" alt="LinkedIn Learning, AI for Senior Managers" class="img_ev3q"></p>
</blockquote>
<p>An average human can type <a href="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fc9pel0p1ygfetfzn4p8z.png" target="_blank" rel="noopener noreferrer">40 words per minute</a> while OpenAI&#x27;s GPT-4 Turbo API can fare a solid 1100 WPM (<a href="https://artificialanalysis.ai/models/gpt-4-turbo/providers" target="_blank" rel="noopener noreferrer">25 tokens per second</a>). LLMs are better typists. Besides, we all see news headlines, watch videos, and see tons of content on how GPT-4 does better than most people in different kinds of tasks and exams.</p>
<blockquote>
<p><strong>Software Developer + AI = more code + better code. Right?</strong></p>
</blockquote>
<p>February 2024 <a href="https://www.teamblind.com/post/Nvidia-ceo-Jensen-Huang-says-programmers-are-obsolete-JUp3O1vs" target="_blank" rel="noopener noreferrer">claim</a> from Nvidia CEO&#x27;s that software devs are obsolete completes the picture.</p>
<p>We&#x27;ve seen many sensational headlines exaggerating LLM capabilities - in many cases when verified they turned out to be exageredted, e.g. <a href="https://www.linkedin.com/posts/maxim-saplin_no-gpt4-cant-ace-mit-activity-7078013877854031872-qd_1?utm_source=share&amp;utm_medium=member_desktop" target="_blank" rel="noopener noreferrer">&quot;No, GPT4 canât ace MIT&quot;</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-limits">LLM Limits<a href="#llm-limits" class="hash-link" aria-label="Direct link to LLM Limits" title="Direct link to LLM Limits">â</a></h2>
<p>The vision of using English as a programming language hasn&#x27;t come true, yet. Let&#x27;s discuss GPTs and LLMs.</p>
<p><strong>Models hallucinate.</strong> My experience, external evidence, and opinions of several AI researchers suggest the problem will stay with us. No surprise Microsoft has an army of <strong>Co</strong>-pilots and not a single <strong>pilot</strong> yet...</p>
<p>Technically speaking <a href="https://www.youtube.com/watch?v=zjkBMFhNj_g&amp;t=538s" target="_blank" rel="noopener noreferrer">100% of what a model generates is hallucination</a>. It just happens that most of the text it hallucinates is grounded in real data and the output happens to be factual and reasonable. Until it doesn&#x27;t. Sometimes parts of the text appear to be false or nonsensical - that is the &quot;LLM hallucinations&quot; in a traditional sense.</p>
<p>There&#x27;s another angle to the problem of hallucinations. It is about LLM seeing something in the context window/prompt that IS NOT there OR being <a href="https://towardsdatascience.com/the-needle-in-a-haystack-test-a94974c1ad38" target="_blank" rel="noopener noreferrer">blind to something in it</a>.</p>
<p>When using GPT-4 for some mundane tasks I see it failing simple instructions or generating garbage quite often. E.g. &quot;check the CSV, do something with the rows&quot; - it could get 40 rows as an input and return 37 IDs (while all rows had those). I&#x27;ve seen many occasions of such failures to follow the instructions, missing prompt data, etc. Hence my skepticism towards <a href="https://www.pinecone.io/blog/rag-study/" target="_blank" rel="noopener noreferrer">claims that RAG is the solution</a> - no, it&#x27;s not. Even having all the factual data in the context window state-of-the-art models fail to account for this data, they do it randomly wrapping in confident verbosity.</p>
<p>Until there&#x27;s a <a href="https://twitter.com/ylecun/status/1667218790625468416" target="_blank" rel="noopener noreferrer">new kind of model architecture</a> and GenAI solutions rely on current architectures we will likely come across <a href="https://www.theguardian.com/world/2023/aug/10/pak-n-save-savey-meal-bot-ai-app-malfunction-recipes" target="_blank" rel="noopener noreferrer">all kinds of crap</a> GPTs might come up with.</p>
<p>In <a href="https://youtu.be/PAVeYUgknMw?t=313" target="_blank" rel="noopener noreferrer">this video</a> the author touches on the research of GPT4 irrationality and demonstrates how sometimes syntax wins over semantics - after all LLMs are next-word generators by design and their nature is rooted in language structure, not meanings.</p>
<p>Until the model can produce hallucination-free and accurate output OR learn its limits of knowledge, and reliably flag parts it is unsure of LLM applications can&#x27;t be watertight - you should always expect some nasty output.</p>
<p>By the way in <a href="https://youtu.be/fE-VC4MZmy0?t=266" target="_blank" rel="noopener noreferrer">this video</a> Google&#x27;s Bard (now Gemini) feature of highlighting the model&#x27;s confidence was tested (spoiler, it failed).</p>
<p><em>On a separate note, I think the whole capacity of LLM to output reasonable text is the emergent ability. Few people expected that the auto-regressive token generator model might turn into the powerhouse GPT3 turned out to be :)</em></p>
<p><strong>Context windows are small</strong>, very small for practical use in AI coding. E.g. GPT-4 with 128k context can only fit <a href="https://dev.to/maximsaplin/gpt-4-128k-context-it-is-not-big-enough-1h02" target="_blank" rel="noopener noreferrer">24 average files from Linux kernel</a>. There are models, such as Claude 3 or Gemini 1.5, that offer 1 million+ context windows in closed beta. But:</p>
<ul>
<li>That&#x27;s still not even close to a typical project into the prompt entirely. In the meantime, the models will rely on text snippets from various files of the solution injected into the prompt with devs hoping RAG can find all relevant and related pieces</li>
<li>Large context comes at a price of (a) more expensive API calls and (b) slower performance - even if you increase tenfold the size of the context window the performance requirements <a href="https://www.cerebras.net/chip/context-is-everything-why-maximum-sequence-length-matters/" target="_blank" rel="noopener noreferrer">will grow 100-fold</a></li>
<li>Even if the above 2 points are solved (super fast super large context windows), remember the hallucinations. The model might still come across an <a href="https://youtu.be/zduSFxRajkE?t=7221" target="_blank" rel="noopener noreferrer">&quot;unstable token&quot;</a> or stumble upon a &quot;SolidGoldMagikarp&quot;(<a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation" target="_blank" rel="noopener noreferrer">https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation</a>) snowballing into a nonsensical mess.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="training-data-considerations">Training Data Considerations<a href="#training-data-considerations" class="hash-link" aria-label="Direct link to Training Data Considerations" title="Direct link to Training Data Considerations">â</a></h2>
<p>LLMs are trained on large bodies of code, God knows which ones. What are your expectations of an average code? Would it be great or just &quot;average&quot; (or mediocre)? Likely training data will have a bias towards open source projects. What are your expectations of open-source projects? Will LLM see tons of tutorial-like small or abandoned repos?</p>
<p>When a LLM produces code it generates it &quot;within the distribution&quot; of data seen. On a large scale, it is not possible to evaluate the quality of code and cherry-pick only best-of-the-best repos and use those as training data.</p>
<p>An assumption about training data and its implication that is easy to verify is old code dominating the datasets. If you used an AI coding assistant it&#x27;s likely you saw some cases when it spit out older versions of libraries. E.g. in my review of <a href="https://dev.to/maximsaplin/exploring-cody-an-ai-coding-assistant-that-knows-your-codebase-17bh" target="_blank" rel="noopener noreferrer">Cody</a> from August 2023 one of the tests was about importing missing dependencies in a Flutter project. The assistant suggested <a href="https://pub.dev/packages/http/versions" target="_blank" rel="noopener noreferrer">http</a> package version 0.13.14 from Oct 4, 2021, while the most recent version available at the time of the test was version 1.1.0 from Jun 26, 2023.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="planting-time-bombs-in-the-code-base">Planting Time-bombs in the Code Base<a href="#planting-time-bombs-in-the-code-base" class="hash-link" aria-label="Direct link to Planting Time-bombs in the Code Base" title="Direct link to Planting Time-bombs in the Code Base">â</a></h2>
<p>OK. Who cares if LLMs hallucinate? Is that such a big deal? In some cases, e.g. code generation, they might do better since code is more structured than natural language. Reviewing the code and fixing a problem shouldn&#x27;t be that hard - reading is faster than writing.</p>
<p>I would argue that <strong>reading code is harder than writing it</strong> - it requires more mental effort. I have seen a lot of reluctance from devs <a href="https://www.youtube.com/watch?v=rR4n-0KYeKQ" target="_blank" rel="noopener noreferrer">doing code reviews</a>. I experienced it personally and can recall the stress of going through unfamiliar code vs. working in flow and enjoying adding new lines to the code I have written before. The same holds for AI-generated code, there&#x27;s a reluctance to review it. &quot;Generate code -&gt; Run it -&gt; See it working -&gt; Ask the model for a fix&quot; a less mentally effortful loop engaging only <a href="https://fs.blog/daniel-kahneman-the-two-systems/" target="_blank" rel="noopener noreferrer">System 1</a> thinking.</p>
<p>Pair this AI-assisted &quot;build - run - fix&quot; loop with over-reliance on technology and you get the complacency. Just like there are accounts of GPS nav leading drivers into all sorts of <a href="https://www.reddit.com/r/doordash/comments/16smyxw/dd_driver_followed_gps_into_a_body_of_water_saved/" target="_blank" rel="noopener noreferrer">water bodies</a> (are blind people allowed to drive?) AI coding can have similar effects on developers.</p>
<p>By the way &quot;LLM09: Overreliance&quot; is part of the Top 10 LLM vulnerabilities by <a href="https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-v1_1.pdf" target="_blank" rel="noopener noreferrer">OWASP</a>.</p>
<p>It is the <strong>convenience</strong> of AI coding, the behaviors it provokes, and human nature -  all of that lead to the risk of nuanced bugs that are missed and discovered further down the line.</p>
<p>Have a look at this <a href="https://madappgang.com/blog/chat-gpt-code-errors/" target="_blank" rel="noopener noreferrer">example</a> of generating a basic JWT authentication in Go. The code builds and runs just fine, yet there are 5 issues spotted by an experienced eye, including using a deprecated library with critical security vulnerability OR &quot;repeating people&#x27;s mistake&quot; by choosing the least secure token type.</p>
<p><a href="https://snyk.io/de/blog/copilot-amplifies-insecure-codebases-by-replicating-vulnerabilities/" target="_blank" rel="noopener noreferrer">Copilot amplifies insecure codebases by replicating vulnerabilities in your projects</a> is a blog post by a security firm that demonstrates how Copilot happily duplicates and multiplies the already existing issues (as seen by AI in the context) in the newly generated code.</p>
<p>There&#x27;s weak evidence of people&#x27;s reluctance to change (and likely to review) the AI-generated code in <a href="https://visualstudiomagazine.com/articles/2024/01/25/copilot-research.aspx" target="_blank" rel="noopener noreferrer">industry data</a>: after 2021 (the start of Copilot era) there&#x27;s more new code being added and more code being copied and pasted compared to code being updated, removed, or rearranged.</p>
<p>Another piece of evidence calling out human laziness and use of GenAI is this <a href="https://dev.to/maximsaplin/llms-commendable-innovative-meticulous-notable-versatile-intricate-impact-f75" target="_blank" rel="noopener noreferrer">recent study</a> which draws a grim picture on what might come next - people behaving as poor students and doing late submissions of something they hastily compiled from the internet.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai-coding-is-great">AI-coding is great!<a href="#ai-coding-is-great" class="hash-link" aria-label="Direct link to AI-coding is great!" title="Direct link to AI-coding is great!">â</a></h2>
<p>With that much skepticism (as it might seem) towards foundational models and their application to coding I can&#x27;t imagine going back. GenAI tools have become an integral part of my workflows, I enjoy AI assistant in my IDE!</p>
<p>It&#x27;s just the sensationalism of media and roaring headlines that made things worse, they widened the gap between what AI can do well and what many people expect.</p>
<p>To me (and at this point) AI assistants are closer to ergonomic tools (like IntelliSense or ReSharper). The are not some autonomous agents that can be delegated with complex tasks, not even the easy ones - we are not there yet. Assistants haven&#x27;t brought many new use cases that are truly groundbreaking in could change the lives of engineers.</p>
<p>With deflated expectations, intuition around capabilities and limitations behind LLMs powering all kinds of copilots you can reach the harmony and see not huge, yet noticeable personal productivity gains.</p>
<p>See my <a href="https://dev.to/maximsaplin/-cursorsh-a-competitor-to-github-copilot-58k4" target="_blank" rel="noopener noreferrer">review of Cursor.sh</a> - a VSCode fork integrating AI coding. I tried to lay out my view on the state of copilots and list what works and what does not.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="outro">Outro<a href="#outro" class="hash-link" aria-label="Direct link to Outro" title="Direct link to Outro">â</a></h2>
<p>AI-assisted coding represents a significant leap forward for software development, but it is not without its challenges. As we integrate these tools into our workflows, we must do so with a critical eye, understanding their limitations and potential risks.</p>
<p>Developers must become the gatekeepers of AI-generated code, ensuring its quality before it becomes part of the products that shape our world. By nurturing a culture of responsibility and discernment, we can leverage AI to enhance our capabilities without compromising our standards or the trust of those who rely on our software.</p>
<p>Being lazy and ignorant of LLM constraints we will amplify the deficiencies GenAI can bring along, pushing the flaws within the generated output that may not manifest until much later.</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a title="Insights and resources for developers leveraging Generative AI" class="tag_zVej tagRegular_sFm0" href="/blog/tags/developers">Developers</a></li><li class="tag_QGVx"><a title="Excelence in SDLC with Generative AI" class="tag_zVej tagRegular_sFm0" href="/blog/tags/xdlc-ai">xdlc.ai</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/blog/welcome"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Welcome</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#change-of-the-paradigm" class="table-of-contents__link toc-highlight">Change of the Paradigm</a></li><li><a href="#llm-limits" class="table-of-contents__link toc-highlight">LLM Limits</a></li><li><a href="#training-data-considerations" class="table-of-contents__link toc-highlight">Training Data Considerations</a></li><li><a href="#planting-time-bombs-in-the-code-base" class="table-of-contents__link toc-highlight">Planting Time-bombs in the Code Base</a></li><li><a href="#ai-coding-is-great" class="table-of-contents__link toc-highlight">AI-coding is great!</a></li><li><a href="#outro" class="table-of-contents__link toc-highlight">Outro</a></li></ul></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2024 xDLC.ai</div></div></div></footer></div>
</body>
</html>