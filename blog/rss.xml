<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="rss.xsl"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>xdlc.ai Blog</title>
        <link>https://epam.github.io/xdlc-ai/blog</link>
        <description>xdlc.ai Blog</description>
        <lastBuildDate>Thu, 12 Dec 2024 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[AI-assisted coding, Sleeping on a Volcano]]></title>
            <link>https://epam.github.io/xdlc-ai/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano</link>
            <guid>https://epam.github.io/xdlc-ai/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano</guid>
            <pubDate>Thu, 12 Dec 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[logo]]></description>
            <content:encoded><![CDATA[<p><img decoding="async" loading="lazy" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4yi7x4r44r6f48rbh72p.png" alt="logo" class="img_ev3q"></p>
<blockquote>
<p>I started this post with the intention to deliver a simple message... AI tools bring convenience, people get lazier and copy/paste hallucinated code, and flaws get missed and not discovered until later. Yet it happened to be longer and deeper.</p>
</blockquote>
<p>If you are working in a large software company and <strong>there's a team requesting an AI Chat Bot</strong> for their enterprise project (e.g. copy-and-paste stack traces while debugging errors)... Or they want to use <strong>AI coding assistant</strong> in their IDEs (and keep the generated code in production Git)... After the question of tools cost is sorted and you are cleared by Finance, you will likely be pulled into some "fear-driven" meeting with legal/compliance/IT-security discussing one of the topics:</p>
<ul>
<li>Data security</li>
<li>Privacy</li>
<li>Copyright</li>
</ul>
<p>Nobody wants to be taken accountable for the (potential) failures brought by GenAI or 3rd parties in the supply chain. Those boring and trivial questions consume most of the time in discussions (is it yet another manifestation of <a href="https://en.wiktionary.org/wiki/bikeshedding" target="_blank" rel="noopener noreferrer">bikeshedding</a>?). Yet a more nuanced (and IMO important) subject how AI can affect the quality of the end product is ignored.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="change-of-the-paradigm">Change of the Paradigm<a href="https://epam.github.io/xdlc-ai/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano#change-of-the-paradigm" class="hash-link" aria-label="Direct link to Change of the Paradigm" title="Direct link to Change of the Paradigm">​</a></h2>
<p>There's a joke: "Before ChatGPT I spent my time writing code. Now I spend it debugging and fixing the generated one".</p>
<p>Providing the dev team with GH CoPilot subscriptions doesn't guarantee getting more with less. It might happen that neither the quality nor quantity of the output will improve. The effects of GenAI adoption in engineering workflows might be more nuanced and deferred.</p>
<p>One popular view on how Generative AI is transforming software development goes as follows: let the engineers focus on the creative aspects of the job and delegate the tedious task of writing code to a GPT/LLM. <strong>This AI-coding paradigm assumes the shift in the dev's job description: from typing in program code to writing instructions and reviewing the generated result, directing the AI model into producing the desired output.</strong></p>
<p>Here's Andrej Karpathy's <a href="https://twitter.com/karpathy/status/1767598414945292695" target="_blank" rel="noopener noreferrer">recent quote</a>:</p>
<blockquote>
<p>In any case, software engineering is on track to change substantially. And it will look a lot more like supervising the automation, while pitching in high-level commands, ideas, or progression strategies, in English.</p>
</blockquote>
<p>And here's a quote from <strong>AI Challenges and Opportunities for Leadership</strong> LinkedIn course (if you haven't heard, LinkedIn recently released <a href="https://www.linkedin.com/business/talent/blog/talent-acquisition/250-free-ai-courses" target="_blank" rel="noopener noreferrer">250 free AI courses</a>):</p>
<blockquote>
<p>"... productivity tools that speed up work while enhancing output quality".
<img decoding="async" loading="lazy" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ulh3m7lej10ly4dqpwpz.png" alt="LinkedIn Learning, AI for Senior Managers" class="img_ev3q"></p>
</blockquote>
<p>An average human can type <a href="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fc9pel0p1ygfetfzn4p8z.png" target="_blank" rel="noopener noreferrer">40 words per minute</a> while OpenAI's GPT-4 Turbo API can fare a solid 1100 WPM (<a href="https://artificialanalysis.ai/models/gpt-4-turbo/providers" target="_blank" rel="noopener noreferrer">25 tokens per second</a>). LLMs are better typists. Besides, we all see news headlines, watch videos, and see tons of content on how GPT-4 does better than most people in different kinds of tasks and exams.</p>
<blockquote>
<p><strong>Software Developer + AI = more code + better code. Right?</strong></p>
</blockquote>
<p>February 2024 <a href="https://www.teamblind.com/post/Nvidia-ceo-Jensen-Huang-says-programmers-are-obsolete-JUp3O1vs" target="_blank" rel="noopener noreferrer">claim</a> from Nvidia CEO's that software devs are obsolete completes the picture.</p>
<p>We've seen many sensational headlines exaggerating LLM capabilities - in many cases when verified they turned out to be exageredted, e.g. <a href="https://www.linkedin.com/posts/maxim-saplin_no-gpt4-cant-ace-mit-activity-7078013877854031872-qd_1?utm_source=share&amp;utm_medium=member_desktop" target="_blank" rel="noopener noreferrer">"No, GPT4 can’t ace MIT"</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-limits">LLM Limits<a href="https://epam.github.io/xdlc-ai/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano#llm-limits" class="hash-link" aria-label="Direct link to LLM Limits" title="Direct link to LLM Limits">​</a></h2>
<p>The vision of using English as a programming language hasn't come true, yet. Let's discuss GPTs and LLMs.</p>
<p><strong>Models hallucinate.</strong> My experience, external evidence, and opinions of several AI researchers suggest the problem will stay with us. No surprise Microsoft has an army of <strong>Co</strong>-pilots and not a single <strong>pilot</strong> yet...</p>
<p>Technically speaking <a href="https://www.youtube.com/watch?v=zjkBMFhNj_g&amp;t=538s" target="_blank" rel="noopener noreferrer">100% of what a model generates is hallucination</a>. It just happens that most of the text it hallucinates is grounded in real data and the output happens to be factual and reasonable. Until it doesn't. Sometimes parts of the text appear to be false or nonsensical - that is the "LLM hallucinations" in a traditional sense.</p>
<p>There's another angle to the problem of hallucinations. It is about LLM seeing something in the context window/prompt that IS NOT there OR being <a href="https://towardsdatascience.com/the-needle-in-a-haystack-test-a94974c1ad38" target="_blank" rel="noopener noreferrer">blind to something in it</a>.</p>
<p>When using GPT-4 for some mundane tasks I see it failing simple instructions or generating garbage quite often. E.g. "check the CSV, do something with the rows" - it could get 40 rows as an input and return 37 IDs (while all rows had those). I've seen many occasions of such failures to follow the instructions, missing prompt data, etc. Hence my skepticism towards <a href="https://www.pinecone.io/blog/rag-study/" target="_blank" rel="noopener noreferrer">claims that RAG is the solution</a> - no, it's not. Even having all the factual data in the context window state-of-the-art models fail to account for this data, they do it randomly wrapping in confident verbosity.</p>
<p>Until there's a <a href="https://twitter.com/ylecun/status/1667218790625468416" target="_blank" rel="noopener noreferrer">new kind of model architecture</a> and GenAI solutions rely on current architectures we will likely come across <a href="https://www.theguardian.com/world/2023/aug/10/pak-n-save-savey-meal-bot-ai-app-malfunction-recipes" target="_blank" rel="noopener noreferrer">all kinds of crap</a> GPTs might come up with.</p>
<p>In <a href="https://youtu.be/PAVeYUgknMw?t=313" target="_blank" rel="noopener noreferrer">this video</a> the author touches on the research of GPT4 irrationality and demonstrates how sometimes syntax wins over semantics - after all LLMs are next-word generators by design and their nature is rooted in language structure, not meanings.</p>
<p>Until the model can produce hallucination-free and accurate output OR learn its limits of knowledge, and reliably flag parts it is unsure of LLM applications can't be watertight - you should always expect some nasty output.</p>
<p>By the way in <a href="https://youtu.be/fE-VC4MZmy0?t=266" target="_blank" rel="noopener noreferrer">this video</a> Google's Bard (now Gemini) feature of highlighting the model's confidence was tested (spoiler, it failed).</p>
<p><em>On a separate note, I think the whole capacity of LLM to output reasonable text is the emergent ability. Few people expected that the auto-regressive token generator model might turn into the powerhouse GPT3 turned out to be :)</em></p>
<p><strong>Context windows are small</strong>, very small for practical use in AI coding. E.g. GPT-4 with 128k context can only fit <a href="https://dev.to/maximsaplin/gpt-4-128k-context-it-is-not-big-enough-1h02" target="_blank" rel="noopener noreferrer">24 average files from Linux kernel</a>. There are models, such as Claude 3 or Gemini 1.5, that offer 1 million+ context windows in closed beta. But:</p>
<ul>
<li>That's still not even close to a typical project into the prompt entirely. In the meantime, the models will rely on text snippets from various files of the solution injected into the prompt with devs hoping RAG can find all relevant and related pieces</li>
<li>Large context comes at a price of (a) more expensive API calls and (b) slower performance - even if you increase tenfold the size of the context window the performance requirements <a href="https://www.cerebras.net/chip/context-is-everything-why-maximum-sequence-length-matters/" target="_blank" rel="noopener noreferrer">will grow 100-fold</a></li>
<li>Even if the above 2 points are solved (super fast super large context windows), remember the hallucinations. The model might still come across an <a href="https://youtu.be/zduSFxRajkE?t=7221" target="_blank" rel="noopener noreferrer">"unstable token"</a> or stumble upon a "SolidGoldMagikarp"(<a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation" target="_blank" rel="noopener noreferrer">https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation</a>) snowballing into a nonsensical mess.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="training-data-considerations">Training Data Considerations<a href="https://epam.github.io/xdlc-ai/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano#training-data-considerations" class="hash-link" aria-label="Direct link to Training Data Considerations" title="Direct link to Training Data Considerations">​</a></h2>
<p>LLMs are trained on large bodies of code, God knows which ones. What are your expectations of an average code? Would it be great or just "average" (or mediocre)? Likely training data will have a bias towards open source projects. What are your expectations of open-source projects? Will LLM see tons of tutorial-like small or abandoned repos?</p>
<p>When a LLM produces code it generates it "within the distribution" of data seen. On a large scale, it is not possible to evaluate the quality of code and cherry-pick only best-of-the-best repos and use those as training data.</p>
<p>An assumption about training data and its implication that is easy to verify is old code dominating the datasets. If you used an AI coding assistant it's likely you saw some cases when it spit out older versions of libraries. E.g. in my review of <a href="https://dev.to/maximsaplin/exploring-cody-an-ai-coding-assistant-that-knows-your-codebase-17bh" target="_blank" rel="noopener noreferrer">Cody</a> from August 2023 one of the tests was about importing missing dependencies in a Flutter project. The assistant suggested <a href="https://pub.dev/packages/http/versions" target="_blank" rel="noopener noreferrer">http</a> package version 0.13.14 from Oct 4, 2021, while the most recent version available at the time of the test was version 1.1.0 from Jun 26, 2023.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="planting-time-bombs-in-the-code-base">Planting Time-bombs in the Code Base<a href="https://epam.github.io/xdlc-ai/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano#planting-time-bombs-in-the-code-base" class="hash-link" aria-label="Direct link to Planting Time-bombs in the Code Base" title="Direct link to Planting Time-bombs in the Code Base">​</a></h2>
<p>OK. Who cares if LLMs hallucinate? Is that such a big deal? In some cases, e.g. code generation, they might do better since code is more structured than natural language. Reviewing the code and fixing a problem shouldn't be that hard - reading is faster than writing.</p>
<p>I would argue that <strong>reading code is harder than writing it</strong> - it requires more mental effort. I have seen a lot of reluctance from devs <a href="https://www.youtube.com/watch?v=rR4n-0KYeKQ" target="_blank" rel="noopener noreferrer">doing code reviews</a>. I experienced it personally and can recall the stress of going through unfamiliar code vs. working in flow and enjoying adding new lines to the code I have written before. The same holds for AI-generated code, there's a reluctance to review it. "Generate code -&gt; Run it -&gt; See it working -&gt; Ask the model for a fix" a less mentally effortful loop engaging only <a href="https://fs.blog/daniel-kahneman-the-two-systems/" target="_blank" rel="noopener noreferrer">System 1</a> thinking.</p>
<p>Pair this AI-assisted "build - run - fix" loop with over-reliance on technology and you get the complacency. Just like there are accounts of GPS nav leading drivers into all sorts of <a href="https://www.reddit.com/r/doordash/comments/16smyxw/dd_driver_followed_gps_into_a_body_of_water_saved/" target="_blank" rel="noopener noreferrer">water bodies</a> (are blind people allowed to drive?) AI coding can have similar effects on developers.</p>
<p>By the way "LLM09: Overreliance" is part of the Top 10 LLM vulnerabilities by <a href="https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-v1_1.pdf" target="_blank" rel="noopener noreferrer">OWASP</a>.</p>
<p>It is the <strong>convenience</strong> of AI coding, the behaviors it provokes, and human nature -  all of that lead to the risk of nuanced bugs that are missed and discovered further down the line.</p>
<p>Have a look at this <a href="https://madappgang.com/blog/chat-gpt-code-errors/" target="_blank" rel="noopener noreferrer">example</a> of generating a basic JWT authentication in Go. The code builds and runs just fine, yet there are 5 issues spotted by an experienced eye, including using a deprecated library with critical security vulnerability OR "repeating people's mistake" by choosing the least secure token type.</p>
<p><a href="https://snyk.io/de/blog/copilot-amplifies-insecure-codebases-by-replicating-vulnerabilities/" target="_blank" rel="noopener noreferrer">Copilot amplifies insecure codebases by replicating vulnerabilities in your projects</a> is a blog post by a security firm that demonstrates how Copilot happily duplicates and multiplies the already existing issues (as seen by AI in the context) in the newly generated code.</p>
<p>There's weak evidence of people's reluctance to change (and likely to review) the AI-generated code in <a href="https://visualstudiomagazine.com/articles/2024/01/25/copilot-research.aspx" target="_blank" rel="noopener noreferrer">industry data</a>: after 2021 (the start of Copilot era) there's more new code being added and more code being copied and pasted compared to code being updated, removed, or rearranged.</p>
<p>Another piece of evidence calling out human laziness and use of GenAI is this <a href="https://dev.to/maximsaplin/llms-commendable-innovative-meticulous-notable-versatile-intricate-impact-f75" target="_blank" rel="noopener noreferrer">recent study</a> which draws a grim picture on what might come next - people behaving as poor students and doing late submissions of something they hastily compiled from the internet.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai-coding-is-great">AI-coding is great!<a href="https://epam.github.io/xdlc-ai/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano#ai-coding-is-great" class="hash-link" aria-label="Direct link to AI-coding is great!" title="Direct link to AI-coding is great!">​</a></h2>
<p>With that much skepticism (as it might seem) towards foundational models and their application to coding I can't imagine going back. GenAI tools have become an integral part of my workflows, I enjoy AI assistant in my IDE!</p>
<p>It's just the sensationalism of media and roaring headlines that made things worse, they widened the gap between what AI can do well and what many people expect.</p>
<p>To me (and at this point) AI assistants are closer to ergonomic tools (like IntelliSense or ReSharper). The are not some autonomous agents that can be delegated with complex tasks, not even the easy ones - we are not there yet. Assistants haven't brought many new use cases that are truly groundbreaking in could change the lives of engineers.</p>
<p>With deflated expectations, intuition around capabilities and limitations behind LLMs powering all kinds of copilots you can reach the harmony and see not huge, yet noticeable personal productivity gains.</p>
<p>See my <a href="https://dev.to/maximsaplin/-cursorsh-a-competitor-to-github-copilot-58k4" target="_blank" rel="noopener noreferrer">review of Cursor.sh</a> - a VSCode fork integrating AI coding. I tried to lay out my view on the state of copilots and list what works and what does not.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="outro">Outro<a href="https://epam.github.io/xdlc-ai/blog/2024/12/12/ai-assisted-coding-sleeping-on-a-volcano#outro" class="hash-link" aria-label="Direct link to Outro" title="Direct link to Outro">​</a></h2>
<p>AI-assisted coding represents a significant leap forward for software development, but it is not without its challenges. As we integrate these tools into our workflows, we must do so with a critical eye, understanding their limitations and potential risks.</p>
<p>Developers must become the gatekeepers of AI-generated code, ensuring its quality before it becomes part of the products that shape our world. By nurturing a culture of responsibility and discernment, we can leverage AI to enhance our capabilities without compromising our standards or the trust of those who rely on our software.</p>
<p>Being lazy and ignorant of LLM constraints we will amplify the deficiencies GenAI can bring along, pushing the flaws within the generated output that may not manifest until much later.</p>]]></content:encoded>
            <category>Developers</category>
            <category>xdlc.ai</category>
        </item>
        <item>
            <title><![CDATA[Welcome]]></title>
            <link>https://epam.github.io/xdlc-ai/blog/welcome</link>
            <guid>https://epam.github.io/xdlc-ai/blog/welcome</guid>
            <pubDate>Wed, 11 Dec 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[intro]]></description>
            <content:encoded><![CDATA[<p><img decoding="async" loading="lazy" alt="intro" src="https://epam.github.io/xdlc-ai/assets/images/image-107c65b200a0b4a21b2ceb0470df640d.png" width="1806" height="568" class="img_ev3q"></p>
<p>Welcome to the xdlc.ai Blog!</p>
<p>In the ever-evolving landscape of software engineering, Generative AI has emerged as a transformative force. As highlighted in our <a href="https://epam.github.io/xdlc-ai/#manifesto">Manifesto</a>, the industry has seen a surge in AI tools, with GitHub Copilot leading the charge. The <a href="https://survey.stackoverflow.co/2024/ai#sentiment-and-usage-ai-select" target="_blank" rel="noopener noreferrer">2024 Stackoverflow Survey</a> reveals that a significant majority of developers are embracing these tools, yet challenges remain in fully leveraging their potential.</p>
<p>At &lt; xdlc.ai /&gt;, we are a collective of passionate software development professionals dedicated to exploring the future of software engineering. Our mission is to share insights, evidence, and recommendations to help you maximize the benefits of Generative AI in your development processes. Our experiences span real production projects, offering a unique perspective on the practical application of AI beyond simple coding tasks.</p>
<p>In our <a href="https://epam.github.io/xdlc-ai/docs/lessons-learned">Lessons Learned</a> document, we delve into the real-world impact of integrating AI tools into the Software Development Life Cycle (SDLC). From boosting productivity within existing teams to addressing human factors in AI adoption, we provide a comprehensive analysis of the promises and realities of Gen AI in SDLC.</p>
<p>Our <a href="https://epam.github.io/xdlc-ai/llms">LLM Leaderboard</a> offers a detailed ranking of Large Language Models, essential components of AI coding assistants. Choosing the right model can be challenging, and our evaluations aim to guide you in making informed decisions.</p>
<p>Similarly, our <a href="https://epam.github.io/xdlc-ai/coding-assistants">Coding Assistants Leaderboard</a> evaluates various AI-driven tools designed to enhance software development. These tools are assessed across multiple categories, ensuring you have the latest insights into their performance and capabilities.</p>
<p>We invite you to join us in navigating the complexities of AI tools, making informed decisions, and integrating them effectively into your SDLC. Together, we can overcome the challenges and pursue excellence in software development with Generative AI.</p>
<p>Thank you for visiting our blog, and we look forward to sharing this journey with you!</p>]]></content:encoded>
            <category>Hello</category>
            <category>xdlc.ai</category>
        </item>
    </channel>
</rss>