<!doctype html>
<html lang="en" dir="ltr" class="mdx-wrapper mdx-page plugin-pages plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.6.3">
<title data-rh="true">LLMs | &lt; xdlc.ai /&gt;</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/xdlc-ai/llms"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="LLMs | &lt; xdlc.ai /&gt;"><meta data-rh="true" name="description" content="Large Language Models are the key ingedient of AI coding assistants, such as Github Copilot or Cursor. Many of coding assistants (e.g. Continue or Aider) allow you pick the model you want to use. However, it is not always easy to choose the right model. This page offers a ranking of the chat LLMs (those ones you instruct to complete a task, not to be confused with auto-completion/TAB models). Our evaluations include hundreds of taks in various categories, such as code tranlsation, generation,documentations and Large Context Instruction Following. The total score in the leaderboard can generalized to the performance of the model when used for software development taks, either used through a chat bot UI or when powering AI-cording assistant."><meta data-rh="true" property="og:description" content="Large Language Models are the key ingedient of AI coding assistants, such as Github Copilot or Cursor. Many of coding assistants (e.g. Continue or Aider) allow you pick the model you want to use. However, it is not always easy to choose the right model. This page offers a ranking of the chat LLMs (those ones you instruct to complete a task, not to be confused with auto-completion/TAB models). Our evaluations include hundreds of taks in various categories, such as code tranlsation, generation,documentations and Large Context Instruction Following. The total score in the leaderboard can generalized to the performance of the model when used for software development taks, either used through a chat bot UI or when powering AI-cording assistant."><link data-rh="true" rel="icon" href="/xdlc-ai/img/favicon.png"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/xdlc-ai/llms"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/xdlc-ai/llms" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/xdlc-ai/llms" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/xdlc-ai/blog/rss.xml" title="&lt; xdlc.ai /&gt; RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/xdlc-ai/blog/atom.xml" title="&lt; xdlc.ai /&gt; Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D1CPVQLTWE"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-D1CPVQLTWE",{anonymize_ip:!0})</script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous">
<link href="https://fonts.googleapis.com/css2?family=Space+Mono:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet"><link rel="stylesheet" href="/xdlc-ai/assets/css/styles.1855dacd.css">
<script src="/xdlc-ai/assets/js/runtime~main.9c39277a.js" defer="defer"></script>
<script src="/xdlc-ai/assets/js/main.f2897ad6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/xdlc-ai/"><b class="navbar__title text--truncate">&lt; xdlc.ai /&gt;</b></a><a class="navbar__item navbar__link" href="/xdlc-ai/docs/Tips-and-tricks">Cookbook</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/xdlc-ai/llms">LLMs</a><a class="navbar__item navbar__link" href="/xdlc-ai/coding-assistants">Coding Assistants</a><a class="navbar__item navbar__link" href="/xdlc-ai/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><main class="container container--fluid margin-vert--lg"><div class="row mdxPageWrapper_j9I6"><div class="col col--8"><article><p>Large Language Models are the key ingedient of AI coding assistants, such as Github Copilot or Cursor. Many of coding assistants (e.g. Continue or Aider) allow you pick the model you want to use. However, it is not always easy to choose the right model. This page offers a ranking of the chat LLMs (those ones you instruct to complete a task, not to be confused with auto-completion/TAB models). Our evaluations include hundreds of taks in various categories, such as code tranlsation, generation,documentations and Large Context Instruction Following. The total score in the leaderboard can generalized to the performance of the model when used for software development taks, either used through a chat bot UI or when powering AI-cording assistant.</p>
<p>The leaderboard is regularly updated, we run our test harness as soon as there&#x27;re major LLM releases. To learn more about the eval, please check <a href="https://github.com/epam/AIRUN-Engineering-Benchmark/tree/main" target="_blank" rel="noopener noreferrer">AI/RUN<sup>TM</sup> Engineering Benchmark</a> repo.</p>
<header><h1>LLM-as-a-Developer Leaderboard</h1></header>
<table role="table"><thead><tr role="row"><th colspan="1" role="columnheader" title="Toggle SortBy" style="cursor:pointer">Model  </th><th colspan="1" role="columnheader" title="Toggle SortBy" style="cursor:pointer">Cost ($)  </th><th colspan="1" role="columnheader" title="Toggle SortBy" style="cursor:pointer">% per $  </th><th colspan="1" role="columnheader" title="Toggle SortBy" style="cursor:pointer">Total Score  </th></tr></thead><tbody role="rowgroup"><tr role="row"><td role="cell">OpenAI o1-mini (2024-09-12)</td><td role="cell">1.46</td><td role="cell">62.88</td><td role="cell">91.7%</td></tr><tr role="row"><td role="cell">Claude 3.5 Sonnet v2</td><td role="cell">0.88</td><td role="cell">102.27</td><td role="cell">89.6%</td></tr><tr role="row"><td role="cell">ChatGPT-4o</td><td role="cell">0.94</td><td role="cell">95.11</td><td role="cell">89.4%</td></tr><tr role="row"><td role="cell">GPT-4o (2024-11-20)</td><td role="cell">0.55</td><td role="cell">161.27</td><td role="cell">88.7%</td></tr><tr role="row"><td role="cell">Claude 3.5 Haiku</td><td role="cell">0.27</td><td role="cell">322.22</td><td role="cell">86.5%</td></tr><tr role="row"><td role="cell">OpenAI o1-preview (2024-09-12)</td><td role="cell">10.18</td><td role="cell">8.38</td><td role="cell">85.2%</td></tr><tr role="row"><td role="cell">Qwen 2.5 Coder 32B</td><td role="cell">0.10</td><td role="cell">824.00</td><td role="cell">82.4%</td></tr><tr role="row"><td role="cell">GPT-4o (2024-08-06)</td><td role="cell">0.50</td><td role="cell">164.40</td><td role="cell">82.2%</td></tr><tr role="row"><td role="cell">Gemini 1.5 Pro (002)</td><td role="cell">0.29</td><td role="cell">277.78</td><td role="cell">81.0%</td></tr><tr role="row"><td role="cell">Grok Beta</td><td role="cell">0.86</td><td role="cell">70.09</td><td role="cell">77.8%</td></tr><tr role="row"><td role="cell">Llama3.1 405B<sup>1</sup></td><td role="cell">0.30</td><td role="cell">238.67</td><td role="cell">71.2%</td></tr><tr role="row"><td role="cell">GPT-4o-mini (0718)</td><td role="cell">0.03</td><td role="cell">1770.00</td><td role="cell">70.8%</td></tr><tr role="row"><td role="cell">GPT-3.5 Turbo<sup>1</sup></td><td role="cell">0.06</td><td role="cell">1015.00</td><td role="cell">60.9%</td></tr><tr role="row"><td role="cell">Llama3 70B<sup>1</sup></td><td role="cell">0.05</td><td role="cell">1194.00</td><td role="cell">59.7%</td></tr><tr role="row"><td role="cell">Claude 3 Opus<sup>1</sup></td><td role="cell">4.84</td><td role="cell">-</td><td role="cell">-</td></tr><tr role="row"><td role="cell">GPT-4o (2024-05-13)<sup>1</sup></td><td role="cell">1.02</td><td role="cell">-</td><td role="cell">-</td></tr><tr role="row"><td role="cell">Gemini 1.5 Pro (0801-exp)<sup>1</sup></td><td role="cell">0.78</td><td role="cell">-</td><td role="cell">-</td></tr><tr role="row"><td role="cell">Gemini 1.5 Pro (0409)<sup>1</sup></td><td role="cell">1.38</td><td role="cell">-</td><td role="cell">-</td></tr></tbody></table>
<blockquote>
<p><sup>1</sup> - Evaluation was done more than 3 month ago, results are outdated</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tbd">TBD<a href="#tbd" class="hash-link" aria-label="Direct link to TBD" title="Direct link to TBD">​</a></h2>
<ul>
<li>How many tests exactly</li>
<li>Add descriptions of columns<!-- -->
<ul>
<li>What is cost?</li>
</ul>
</li>
<li>Give samples of prompts/tasks and outputs, how are the evaludated exactly</li>
<li>Give breakdown of individual categories</li>
</ul></article></div><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#tbd" class="table-of-contents__link toc-highlight">TBD</a></li></ul></div></div></div></main></div><footer class="footer"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 xDLC.ai</div></div></div></footer></div>
</body>
</html>